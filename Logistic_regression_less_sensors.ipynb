{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original model with less sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets without day 0 \n",
    "import pandas as pd\n",
    "Imputed_test_set = pd.read_csv(\"Data/Imputed_test_set.csv\")\n",
    "Imputed_train_set = pd.read_csv(\"Data/Imputed_train_set.csv\")\n",
    "Imputed_train_set_up = pd.read_csv(\"Data/Imputed_train_set_up.csv\")\n",
    "Imputed_validation_set = pd.read_csv(\"Data/Imputed_validation_set.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting x and y-values as model input. Sequential sensordata is stored in a 3d matrix of 22 days per 5 features per 365 cows.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#extracting all unique combinations of cow and calving moment \n",
    "Unique_Calvings = Imputed_train_set[['AnimalEartag', 'PaperRecordedCalvingDate']].drop_duplicates() \n",
    "\n",
    "#define sensors\n",
    "feature_names = [\"WalkingTimeMinutesPerDay\", \"EatingTimeMinutesPerDay\", \"LyingTimeMinutesPerDay\", \"StandingTimeMinutesPerDay\", \"RuminationTimeMinutesPerDay\"]\n",
    "\n",
    "#create empty lists per feature to store variables\n",
    "AnimalEartag_list = [] \n",
    "PaperRecordedCalvingDate_list = []\n",
    "CalciumValue_list = []\n",
    "Calciumcluster_list = []\n",
    "BCS_lijst = []\n",
    "Loco_lijst = []\n",
    "SensorWaardes_list = np.zeros((365,21,5)) #define matrix size for sequential features\n",
    "j = 0\n",
    "\n",
    "#itterating through the dataset in order to extract x and y for each cow \n",
    "for index, (AnimalEartag, PaperRecordedCalvingDate) in Unique_Calvings.iterrows():\n",
    "    filter1 = Imputed_train_set['AnimalEartag'] == AnimalEartag\n",
    "    filter2 = PaperRecordedCalvingDate == Imputed_train_set['PaperRecordedCalvingDate']\n",
    "    df_calving = Imputed_train_set[filter1 & filter2]\n",
    "    Loco = df_calving['FirstLocomotionScore'].max()\n",
    "    BCS =  df_calving['FirstBCSScore'].max()\n",
    "    cacluster = df_calving['Calciumcluster'].iloc[-1] \n",
    "    ca = df_calving['Cut_Off'].iloc[-1]\n",
    "    sw = df_calving[feature_names]\n",
    "  \n",
    "    #convert to numpy\n",
    "    sw_numpy = np.array(sw)\n",
    "    #add to list \n",
    "    AnimalEartag_list.append(AnimalEartag)\n",
    "    PaperRecordedCalvingDate_list.append(PaperRecordedCalvingDate)\n",
    "    CalciumValue_list.append(ca)\n",
    "    Calciumcluster_list.append(cacluster)\n",
    "    BCS_lijst.append((BCS))\n",
    "    Loco_lijst.append((Loco))\n",
    "   \n",
    "    SensorWaardes_list[j] = sw_numpy\n",
    "    j = j + 1\n",
    " \n",
    "#convert to numpy arrays\n",
    "x_train = np.array(SensorWaardes_list)\n",
    "y_train = np.asarray(Calciumcluster_list)\n",
    "y_train2 = np.asarray(CalciumValue_list) #alternatieve y-waardes op basis van een calciumcut-off\n",
    "x_BCS = np.asarray(BCS_lijst)\n",
    "x_Loco = np.asarray(Loco_lijst)\n",
    "x_static = np.stack((x_BCS, x_Loco), axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONEHOTENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calvingseason and parity are cathegorial variables, however the models functions on numerical variables only, therefore the variables are converted into binairy variables using the sklearn onehotencoder. Each category gets its own colummn and the column of the category that is true gets a one, all other get a zero.     \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#extract value for each cow\n",
    "static = Imputed_train_set.groupby(['AnimalEartag', 'PaperRecordedCalvingDate']).first()\n",
    "#convert to numpy\n",
    "season = static['CalvingSeason'].to_numpy()\n",
    "Parity = static['Parity'].to_numpy()\n",
    "CalciumDaysInMilk = static['CalciumDaysInMilk'].to_numpy()\n",
    "#define labelencoder\n",
    "labelEnc = LabelEncoder()\n",
    "#fit and apply\n",
    "x_enc = labelEnc.fit_transform(season)\n",
    "x_enc = x_enc.reshape(len(x_enc), 1) \n",
    "onehotEnc = OneHotEncoder(sparse=False)\n",
    "season_encoded = onehotEnc.fit_transform(x_enc)\n",
    "x_enc_P = labelEnc.fit_transform(Parity)\n",
    "x_enc_P = x_enc_P.reshape(len(x_enc_P), 1) \n",
    "parity_encoded = onehotEnc.fit_transform(x_enc_P)\n",
    "#combine season, parity and day of measurement into one numpy array \n",
    "x_static_lean = np.column_stack([season_encoded, parity_encoded, CalciumDaysInMilk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BCS and Locomotion score was not measured for every cow, therefore some cows have a null value. The null values are replaced by the value that is most frequent in that colummn. \n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_freq = SimpleImputer(missing_values=0.0, strategy='most_frequent')\n",
    "imp_freq.fit(x_static)\n",
    "x_static = imp_freq.transform(x_static)\n",
    "#all static features are added up into one numpy array \n",
    "x_Static = np.column_stack([x_static, season_encoded, parity_encoded, CalciumDaysInMilk]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampled trainset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this train set is upsampled, it is impossible to filter on animal eartag and paperrecordedcalvingdate (some cows of cathegory 1 are duplicated and therefore no longer unique) therefore a new column was introduced while performing upsampling called 'Samplenumber' In order to extract an x and an y per sample, an itteration is performed based on samplenumber. \n",
    "Unique_Calvings = Imputed_train_set_up['SampleNumber'].drop_duplicates()\n",
    "\n",
    "\n",
    "#creating empty lists, pay attention to the increased matrix size and the addition of a list for samplenumber\n",
    "SampleNumber_list = []\n",
    "CalciumValue_list = []\n",
    "Calciumcluster_list = []\n",
    "SensorWaardes_list = np.zeros((534,21,5)) #534 cows, 21 days, 5 sensors\n",
    "BCS_lijst = []\n",
    "Loco_lijst = []\n",
    "j = 0\n",
    "for s in range(len(Unique_Calvings)):\n",
    "    filter = Imputed_train_set_up['SampleNumber'] == s\n",
    "    df_calving = Imputed_train_set_up[filter]\n",
    "    Loco = df_calving['FirstLocomotionScore'].max()\n",
    "    BCS =  df_calving['FirstBCSScore'].max()\n",
    "    i = 1\n",
    "    cacluster = df_calving['Calciumcluster'].iloc[-i]\n",
    "    ca = df_calving['Cut_Off'].iloc[-i]\n",
    "    i = i + 1 #prevents infinite loop\n",
    "  \n",
    "    sw = df_calving[feature_names]\n",
    "  \n",
    "    #convert to numpy\n",
    "    sw_numpy = np.array(sw)\n",
    "    #add to list\n",
    "    SampleNumber_list.append(s)\n",
    "    CalciumValue_list.append(ca)\n",
    "    Calciumcluster_list.append(cacluster)\n",
    "    BCS_lijst.append((BCS))\n",
    "    Loco_lijst.append((Loco))\n",
    "  \n",
    "    SensorWaardes_list[j] = sw_numpy\n",
    "    j = j + 1\n",
    "\n",
    "#transform to numpy array\n",
    "x_train_up = np.array(SensorWaardes_list)\n",
    "y_train_up = np.asarray(Calciumcluster_list)\n",
    "y_train2_up =np.asarray(CalciumValue_list)\n",
    "x_BCS_up = np.asarray(BCS_lijst) #BCS end dry period \n",
    "x_Loco_up = np.asarray(Loco_lijst) #locomotionscore end dry period\n",
    "x_static_up = np.stack((x_BCS_up, x_Loco_up), axis = 1) #combining BCS and Locomotion in order to be able to perform upsampling efficiently"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONEHOTENCODER upsampled trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding upsampled train set\n",
    "#Calvingseason and parity are cathegorial variables, however the models functions on numerical variables only, therefore the variables are converted into binairy variables using the sklearn onehotencoder. Each category gets its own colummn and the column of the category that is true gets a one, all other get a zero.\n",
    "#based on samplenumber instead of animaleartag due to the upsampling \n",
    "static = Imputed_train_set_up.groupby(['SampleNumber']).first()\n",
    "#convert to numpy arrays\n",
    "season = static['CalvingSeason'].to_numpy()\n",
    "Parity = static['Parity'].to_numpy()\n",
    "CalciumDaysInMilk_up = static['CalciumDaysInMilk'].to_numpy()\n",
    "#define encoder\n",
    "labelEnc = LabelEncoder()\n",
    "#fit and apply\n",
    "x_enc = labelEnc.fit_transform(season)\n",
    "x_enc = x_enc.reshape(len(x_enc), 1) \n",
    "onehotEnc = OneHotEncoder(sparse=False)\n",
    "season_encoded_up = onehotEnc.fit_transform(x_enc)\n",
    "x_enc_P = labelEnc.fit_transform(Parity)\n",
    "x_enc_P = x_enc_P.reshape(len(x_enc_P), 1) \n",
    "parity_encoded_up = onehotEnc.fit_transform(x_enc_P)\n",
    "x_static_up = imp_freq.transform(x_static_up)\n",
    "#combine parity, calving season and day of measurement\n",
    "x_static_up_lean = np.column_stack([season_encoded_up, parity_encoded_up, CalciumDaysInMilk_up])\n",
    "#combine all static features into one array\n",
    "x_Static_up = np.column_stack([x_static_up, season_encoded_up, parity_encoded_up, CalciumDaysInMilk_up]) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validationset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting all unique combinations of cow and calving moment  \n",
    "Unique_Calvings_Val = Imputed_validation_set[['AnimalEartag', 'PaperRecordedCalvingDate']].drop_duplicates()\n",
    "\n",
    "\n",
    "AnimalEartagV_list = []\n",
    "PaperRecordedCalvingDateV_list = []\n",
    "CalciumValueV_list = []\n",
    "CalciumclusterV_list = []\n",
    "BCS_lijst = []\n",
    "Loco_lijst = []\n",
    "SensorWaardesV_list = np.zeros((122,21,5)) #122 cows, 21 days, 5 sensors\n",
    "j = 0\n",
    "for index, (AnimalEartag, PaperRecordedCalvingDate) in Unique_Calvings_Val.iterrows():\n",
    "    filter1 = Imputed_validation_set['AnimalEartag'] == AnimalEartag\n",
    "    filter2 = PaperRecordedCalvingDate == Imputed_validation_set['PaperRecordedCalvingDate']\n",
    "    df_calving_val = Imputed_validation_set[filter1 & filter2]\n",
    "    i = 1\n",
    "    Loco = df_calving_val['FirstLocomotionScore'].max()\n",
    "    BCS =  df_calving_val['FirstBCSScore'].max()\n",
    "    caV = df_calving_val['Cut_Off'].iloc[-i]\n",
    "    caclusterV = df_calving_val['Calciumcluster'].iloc[-i]\n",
    "    swV = df_calving_val[feature_names]\n",
    "  \n",
    "    #convert to numpy\n",
    "    swV_numpy = np.array(swV)\n",
    "    #add to list \n",
    "    AnimalEartagV_list.append(AnimalEartag)\n",
    "    PaperRecordedCalvingDateV_list.append(PaperRecordedCalvingDate)\n",
    "    CalciumValueV_list.append(caV)\n",
    "    CalciumclusterV_list.append(caclusterV)\n",
    "    BCS_lijst.append((BCS))\n",
    "    Loco_lijst.append((Loco))\n",
    "    \n",
    "    SensorWaardesV_list[j] = swV_numpy\n",
    "    j = j + 1\n",
    "\n",
    "#convert to numpy \n",
    "x_val = np.array(SensorWaardesV_list)\n",
    "y_val2 = np.asarray(CalciumValueV_list)\n",
    "y_val = np.asarray(CalciumclusterV_list)\n",
    "x_BCS = np.asarray(BCS_lijst)\n",
    "x_Loco = np.asarray(Loco_lijst)\n",
    "#stack BCS en locomotion score \n",
    "x_static_val = np.stack((x_BCS, x_Loco), axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONEHOTENCODER validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding validation\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "static = Imputed_validation_set.groupby(['AnimalEartag', 'PaperRecordedCalvingDate']).first()\n",
    "season = static['CalvingSeason'].to_numpy()\n",
    "Parity = static['Parity'].to_numpy()\n",
    "CalciumDaysInMilk = static['CalciumDaysInMilk'].to_numpy()\n",
    "labelEnc = LabelEncoder()\n",
    "x_enc = labelEnc.fit_transform(season)\n",
    "x_enc = x_enc.reshape(len(x_enc), 1) \n",
    "onehotEnc = OneHotEncoder(sparse=False)\n",
    "season_encoded = onehotEnc.fit_transform(x_enc)\n",
    "x_enc_P = labelEnc.fit_transform(Parity)\n",
    "x_enc_P = x_enc_P.reshape(len(x_enc_P), 1) \n",
    "parity_encoded = onehotEnc.fit_transform(x_enc_P)\n",
    "#combine static features \n",
    "x_static_val_lean = np.column_stack([season_encoded, parity_encoded, CalciumDaysInMilk])\n",
    "#impute missing BCS and Locomotion scores \n",
    "x_static_val = imp_freq.transform(x_static_val)\n",
    "# combine BCS and Locomotion scores with the other static features\n",
    "x_Static_val = np.column_stack([x_static_val, season_encoded, parity_encoded,CalciumDaysInMilk]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting all unique combinations of cow and calving moment\n",
    "Unique_Calvings_Test = Imputed_test_set[['AnimalEartag', 'PaperRecordedCalvingDate']].drop_duplicates()\n",
    "\n",
    "AnimalEartag_Test_list = []\n",
    "PaperRecordedCalvingDate_Test_list = []\n",
    "CalciumValue_Test_list = []\n",
    "Calciumcluster_Test_list = []\n",
    "BCS_lijst = []\n",
    "Loco_lijst = []\n",
    "SensorWaardes_Test_list = np.zeros((122,21,5))\n",
    "k = 0\n",
    "for index, (AnimalEartag, PaperRecordedCalvingDate) in Unique_Calvings_Test.iterrows():\n",
    "    filter1 = Imputed_test_set['AnimalEartag'] == AnimalEartag\n",
    "    filter2 = PaperRecordedCalvingDate == Imputed_test_set['PaperRecordedCalvingDate']\n",
    "    df_calving_test = Imputed_test_set[filter1 & filter2]\n",
    "    Loco = df_calving_test['FirstLocomotionScore'].max()\n",
    "    BCS =  df_calving_test['FirstBCSScore'].max()\n",
    "    i = 1\n",
    "    catest = df_calving_test['Cut_Off'].iloc[-i]\n",
    "    caclustertest = df_calving_test['Calciumcluster'].iloc[-i]\n",
    "    a = df_calving_test['CalvingSeason'].dropna()\n",
    "  \n",
    "    swtest = df_calving_test[feature_names]\n",
    "\n",
    "    #convert to numpy\n",
    "    swtest_numpy = np.array(swtest)\n",
    "\n",
    "    #add to list \n",
    "    AnimalEartag_Test_list.append(AnimalEartag)\n",
    "    PaperRecordedCalvingDate_Test_list.append(PaperRecordedCalvingDate)\n",
    "    CalciumValue_Test_list.append(catest)\n",
    "    Calciumcluster_Test_list.append(caclustertest)\n",
    "    BCS_lijst.append((BCS))\n",
    "    Loco_lijst.append((Loco))\n",
    "    SensorWaardes_Test_list[k] = swtest_numpy\n",
    "    k = k + 1\n",
    "\n",
    "\n",
    "x_test = np.asarray(SensorWaardes_Test_list)\n",
    "y_test2 = np.asarray(CalciumValue_Test_list)\n",
    "y_test = np.asarray(Calciumcluster_Test_list)\n",
    "x_BCS = np.asarray(BCS_lijst)\n",
    "x_Loco = np.asarray(Loco_lijst)\n",
    "x_static_test = np.stack((x_BCS, x_Loco), axis = 1)\n",
    "#impute missing BCS and Locomotion scores\n",
    "x_static_test = imp_freq.transform(x_static_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding test set\n",
    "static = Imputed_test_set.groupby(['AnimalEartag', 'PaperRecordedCalvingDate']).first()\n",
    "season = static['CalvingSeason'].to_numpy()\n",
    "Parity = static['Parity'].to_numpy()\n",
    "CalciumDaysInMilk = static['CalciumDaysInMilk'].to_numpy()\n",
    "labelEnc = LabelEncoder()\n",
    "x_enc = labelEnc.fit_transform(season)\n",
    "x_enc = x_enc.reshape(len(x_enc), 1) \n",
    "onehotEnc = OneHotEncoder(sparse=False)\n",
    "season_encoded = onehotEnc.fit_transform(x_enc)\n",
    "x_enc_P = labelEnc.fit_transform(Parity)\n",
    "x_enc_P = x_enc_P.reshape(len(x_enc_P), 1) \n",
    "parity_encoded = onehotEnc.fit_transform(x_enc_P)\n",
    "#combine static features\n",
    "x_static_test_lean = np.column_stack([season_encoded, parity_encoded, CalciumDaysInMilk])\n",
    "# combine static features with BCS and Locomotion scores\n",
    "x_Static_test = np.column_stack([x_static_test, season_encoded, parity_encoded, CalciumDaysInMilk]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOOTSTRAPPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XgBoost and Deep learning models have a form of randomness in their initialisation. The exact same model structure with the same training data may therefore give different results each time it is run. In order to be able to compare different models, model performance is not objective enough since it can differ with the same model and could be a high value simply because you were lucky. To compansate for this behaviour a second metric is proposed to compare models; the variance of the model. When a model has high variance, the chances are higher that a high value is obtained by luck and it could be that the second time the model is run, the exact same model results in dramaticly low performance metrics. To be able to measure varriance bootstraps are built, bootstraps are samples from the validation set with the same size as the validation set but acquired with sampling with replacement. Therefore the same model can be tested on multiple validation sets and the results can be compared and the SD calculated. \n",
    "\n",
    "#define function for creating bootstraps\n",
    "def create_bootstrap(x_sensor,x_static,y1, y2):\n",
    "    #initialise empty list for bootstraps\n",
    "    bootstrap_x_sensor = []\n",
    "    bootstrap_x_static = []\n",
    "    bootstrap_y1 = []\n",
    "    bootstrap_y2 = []\n",
    "    \n",
    "    #required length of bootstrap \n",
    "    len_val = x_val.shape[0]\n",
    "    \n",
    "    #get random observation \n",
    "    for i in range(len_val):\n",
    "        # get random index\n",
    "        random_idx = np.random.choice(range(len_val), 1)\n",
    "\t\t# get random observation\n",
    "        random_x_sensor = x_sensor[random_idx]\n",
    "        random_x_static = x_static[random_idx]\n",
    "        random_y1 = y1[random_idx]\n",
    "        random_y2 = y2[random_idx]\n",
    "        \n",
    "\t\t# add random observation to bootstrap\n",
    "        bootstrap_x_sensor.append(random_x_sensor)\n",
    "        bootstrap_x_static.append(random_x_static)\n",
    "        bootstrap_y1.append(random_y1)\n",
    "        bootstrap_y2.append(random_y2)\n",
    "        \n",
    "\t# convert to numpy\n",
    "    bootstrap_x_sensor = np.asarray(bootstrap_x_sensor) \n",
    "    bootstrap_x_static = np.asarray(bootstrap_x_static)\n",
    "    bootstrap_y1 = np.asarray(bootstrap_y1)\n",
    "    bootstrap_y2 = np.asarray(bootstrap_y2)\n",
    "\n",
    "\t# return\t\n",
    "    return(bootstrap_x_sensor, bootstrap_x_static, bootstrap_y1, bootstrap_y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to create bootstraps\n",
    "def create_bootstraps(x_sensor,x_static,y1, y2, number_bootstraps):\n",
    "\t\n",
    "# initialize bootstrap containers\n",
    "    bootstrap_container_x_sensor = []\n",
    "    bootstrap_container_x_static = []\n",
    "    bootstrap_container_y1 = []\n",
    "    bootstrap_container_y2 = []\n",
    "\t\t\n",
    "\t# create n bootstrap\n",
    "    for i in range(number_bootstraps):\n",
    "\t\t# get bootstrap\n",
    "        bootstrap_x_sensor, bootstrap_x_static, bootstrap_y1, bootstrap_y2 = create_bootstrap(x_sensor,x_static,y1, y2)\n",
    "\t\t# add to container\n",
    "        bootstrap_container_x_sensor.append(bootstrap_x_sensor)\n",
    "        bootstrap_container_x_static.append(bootstrap_x_static)\n",
    "        bootstrap_container_y1.append(bootstrap_y1)\n",
    "        bootstrap_container_y2.append(bootstrap_y2)\n",
    "\n",
    "\t# return\n",
    "    return(bootstrap_container_x_sensor, bootstrap_container_x_static, bootstrap_container_y1, bootstrap_container_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to evaluate model \n",
    "def evaluate_model(model, bootstrap_container_x_sensor, bootstrap_container_x_static, bootstrap_container_y1, bootstrap_container_y2):\n",
    "\n",
    "\t# initialize evaluation container\n",
    "    performance_container = []\n",
    "\n",
    "\t# loop through bootstraps\n",
    "    for i in range(len(bootstrap_container_x_sensor)):\n",
    "\n",
    "\t\t# get X\n",
    "        bootstrap_x_sensor = bootstrap_container_x_sensor[i]\n",
    "        bootstrap_x_static = bootstrap_container_x_static[i]\n",
    "\t\t# get y\n",
    "        bootstrap_y1 = bootstrap_container_y1[i]\n",
    "        bootstrap_y2 = bootstrap_container_y2[i]\n",
    "        #reshape x from 3d to 2d for machine learning \n",
    "        bootstrap_x_sensor = bootstrap_x_sensor.reshape((bootstrap_x_sensor.shape[0], (bootstrap_x_sensor.shape[1]*bootstrap_x_sensor.shape[2])))\n",
    "        bootstrap_x_static = bootstrap_x_static.reshape(bootstrap_x_static.shape[0], (bootstrap_x_static.shape[1]*bootstrap_x_static.shape[2]))\n",
    "\t\t# get predictions #depending on model to evaluate, for some models static features need to be added, for log reg model do not use predict but predict_proba  \n",
    "        preds = model.predict_proba(bootstrap_x_sensor)    \n",
    "\t\t# get metric # first choose witch y set to test 1 = clustered, 2 = cut-off\n",
    "        auc = roc_auc_score(bootstrap_y2, preds[:, 1])\n",
    "        \n",
    "\t\t# add to container\n",
    "        performance_container.append(auc)\n",
    "      \n",
    "\t# return\n",
    "    return(performance_container)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten numpy array \n",
    "#necessairy beceause machine learning models can not funtion on 3d data \n",
    "x_Train = x_train.reshape(x_train.shape[0], (x_train.shape[1]*x_train.shape[2]))\n",
    "x_Train_up = x_train_up.reshape(x_train_up.shape[0], (x_train_up.shape[1]*x_train_up.shape[2])) \n",
    "x_Test = x_test.reshape(x_test.shape[0], (x_test.shape[1]*x_test.shape[2]))\n",
    "x_Val = x_val.reshape(x_val.shape[0], (x_val.shape[1]*x_val.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add static features to the model imput \n",
    "x_train_sensor_static = np.column_stack([x_Train, x_static_lean])\n",
    "x_val_sensor_static = np.column_stack([x_Val, x_static_val_lean])\n",
    "x_test_sensor_static = np.column_stack([x_Test, x_static_test_lean])\n",
    "x_train_sensor_static_up = np.column_stack([x_Train_up, x_static_up_lean])\n",
    "x_train_plus = np.column_stack([x_Train, x_Static])\n",
    "x_val_plus = np.column_stack([x_Val, x_Static_val])\n",
    "x_test_plus = np.column_stack([x_Test, x_Static_test])\n",
    "x_train_plus_up = np.column_stack([x_Train_up, x_Static_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class weight options\n",
    "cw1 = {0:1, 1:1}  \n",
    "cw2 = {0:1, 1:2}\n",
    "cw3 = {0:1, 1:3}\n",
    "cw4 = {0:1, 1:4}\n",
    "cw5 = {0:1, 1:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def parameters to tune\n",
    "p_x = [x_train_plus, x_train_plus_up]\n",
    "p_cw = [cw1, cw2, cw3, cw4, cw5]\n",
    "p_y = [y_train, y_train_up]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#loop to tune class weight and x-set, max-iter replaced by 100 which is the default value\n",
    "results = []\n",
    "for i in range(len(p_x)):\n",
    "    for j in range(len(p_cw)):\n",
    "        logisticmodel = LogisticRegression(random_state=0, solver = 'liblinear', max_iter = 100, class_weight = p_cw[j]).fit(p_x[i], p_y[i])    \n",
    "        pred_proba = logisticmodel.predict_proba(x_val_plus)\n",
    "        results.append({\n",
    "        'auc' : roc_auc_score(y_val, pred_proba[:, 1]),\n",
    "        'average_precision' : average_precision_score(y_val, pred_proba[:, 1]),     \n",
    "        'x' : p_x[i],\n",
    "        'cw' : p_cw[j]\n",
    "    })\n",
    "#convert to DF\n",
    "Results = pd.DataFrame(results)\n",
    "#sort modelresults\n",
    "Results = Results.sort_values(by='auc', ascending=False)      \n",
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#add weights for class inbalance\n",
    "class_weights = {0:1, 1:3}\n",
    "#define model\n",
    "logisticmodel = LogisticRegression(random_state=0, solver = 'liblinear', max_iter = 100, class_weight = class_weights).fit(x_train_sensor_static_up, y_train2_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance metrics test set \n",
    "pred_proba = logisticmodel.predict_proba(x_test_sensor_static)\n",
    "auc = roc_auc_score(y_test2, pred_proba[:, 1])\n",
    "average_precision = average_precision_score(y_test2, pred_proba[:, 1])\n",
    "print(auc, average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logisticmodel.predict(x_test_sensor_static)\n",
    "pred_proba = logisticmodel.predict_proba(x_test_sensor_static)\n",
    "display(pred_proba[:, 1])\n",
    "\n",
    "#visualize performance\n",
    "from sklearn.metrics import auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test2, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "print(classification_report(y_test2, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated performance metrics \n",
    "from sklearn.metrics import average_precision_score, auc, f1_score\n",
    "sensitiviteit = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "specificiteit = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "ppv = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "auc = roc_auc_score(y_test2, pred_proba[:, 1])\n",
    "MA = logisticmodel.score(x_test_sensor_static, y_test2) #mean accuracy #het percentage wat het model goed geraden heeft \n",
    "average_precision = average_precision_score(y_test2, pred_proba[:, 1])\n",
    "f1_score = f1_score(y_test2, pred)\n",
    "print('sensitiviteit =', sensitiviteit, 'specificiteit =', specificiteit, 'ppv =', ppv, 'AUC =', auc, 'Mean accuracy =', MA, 'average_precision =', average_precision, 'F1_score =', f1_score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model with bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #create 50 bootstraps for machine learning (different due to flattened x-values)\n",
    "Bootstrap_x_sensor_flat, Bootstrap_x_static, Bootstrap_y1, Bootstrap_y2  = create_bootstraps(x_val_plus, x_Static_val, y_val, y_val2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstrapping, evaluate model\n",
    "Bootstrap_performance = evaluate_model(logisticmodel, Bootstrap_x_sensor_flat, Bootstrap_x_static, Bootstrap_y1, Bootstrap_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean and variance performance bootstrapping\n",
    "Mean_performance = np.mean(Bootstrap_performance)\n",
    "SD_performance = np.std(Bootstrap_performance)\n",
    "df = pd.DataFrame(Bootstrap_performance, columns = ['AUC'])\n",
    "# display(df)\n",
    "Mean_performance, SD_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
